{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ecabf6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96ecabf6",
    "outputId": "a0d14e58-d73a-4ddc-aa82-2f82e010a264"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import operator\n",
    "import joblib\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import shutil\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as k\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import string\n",
    "letters = string.ascii_uppercase\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bkfuVwvWuyYD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bkfuVwvWuyYD",
    "outputId": "61fd374b-00ee-4636-ec29-5e9c3795f841"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VhhtN7bVuSc2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VhhtN7bVuSc2",
    "outputId": "d7dc861c-7e65-41e5-d5c3-ffe6d763220e"
   },
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/CODE/CondVAEmelspec/\n",
    "\n",
    "from generator import DataGenerator\n",
    "from musicnn_tags import musicnn_tags as musicnn_tags_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RP-kzvGBlP-o",
   "metadata": {
    "id": "RP-kzvGBlP-o"
   },
   "outputs": [],
   "source": [
    "# PATHS\n",
    "MODEL_PATH = \"/content/drive/MyDrive/CODE/CondVAEmelspec/models/simple_vae/\"\n",
    "SPECTROGRAMS_PATH = \"/content/drive/MyDrive/CODE/CondVAEmelspec/data/spectrograms/\"\n",
    "TAGS_PATH = \"/content/drive/MyDrive/CODE/CondVAEmelspec/data/tags/\"\n",
    "GEN_PATH = '/content/drive/MyDrive/CODE/CondVAEmelspec/data/generations/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7LRC-rXaBXg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c7LRC-rXaBXg",
    "outputId": "33a19bf5-2070-4626-f0c4-b80a8a7f92e0"
   },
   "outputs": [],
   "source": [
    "N_data_tot = os.listdir(SPECTROGRAMS_PATH)\n",
    "print('Dataset size:', len(N_data_tot))\n",
    "\n",
    "# set number of data to train with\n",
    "N = 5000\n",
    "print('training on:', N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeec240b",
   "metadata": {
    "id": "eeec240b"
   },
   "outputs": [],
   "source": [
    "def load_dataset(N):\n",
    "\n",
    "    melspecs = os.listdir(SPECTROGRAMS_PATH)\n",
    "    melspecs = [i for i in melspecs if '.npy' in i]\n",
    "\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    \n",
    "    for i in tqdm(melspecs[:N]):\n",
    "        \n",
    "        try:\n",
    "        \n",
    "            spec_file = os.path.join(SPECTROGRAMS_PATH, i)\n",
    "            arr = np.load(spec_file)\n",
    "\n",
    "            tags_file = os.path.join(TAGS_PATH, i)\n",
    "            v = np.load(tags_file)\n",
    "            \n",
    "            # take top N tags only\n",
    "            v = list(v)\n",
    "            d = dict(zip(musicnn_tags_all, v))\n",
    "            D = dict(sorted(d.items(),key=operator.itemgetter(1),reverse=True))\n",
    "            tags = list(D.keys())[:1]\n",
    "            \n",
    "            #labels_to_keep = ['techno', 'drums', 'electronic', 'slow']\n",
    "\n",
    "            if arr.shape == (96, 188):# and tags[0] in labels_to_keep:\n",
    "                x_train.append(arr)\n",
    "                y_train.extend(tags)\n",
    "                \n",
    "        except Exception as e:\n",
    "            pass\n",
    "    \n",
    "    x_train = np.array(x_train)\n",
    "    \n",
    "    # NORMALIZE SPECTROGRAMS\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    x_train = min_max_scaler.fit_transform(x_train.reshape(-1, x_train.shape[-1])).reshape(x_train.shape)\n",
    "    \n",
    "    # reshape\n",
    "    x_train = x_train.reshape(x_train.shape[0], -1).astype('float32') #/ 255\n",
    "    \n",
    "    all_labels = list(set(y_train))\n",
    "\n",
    "    le = LabelBinarizer()\n",
    "    transfomed_label = le.fit_transform(y_train)\n",
    "    \n",
    "    y_train = np.array(transfomed_label)\n",
    "    \n",
    "    return x_train, y_train, le, min_max_scaler, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4814525",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373,
     "referenced_widgets": [
      "14704cfcae504cf884a9fb606ee1c22e",
      "d591c34a6fc645ffbb690d058cd10898",
      "547d6c8a2ce34c73a304b1779ce50878",
      "7e4f2ecbbfed4c09b568afbaa7547866",
      "7cf1bf0ba5a4492cacd8151e4cbab1d4",
      "072b13566d0c454781d3bdc78be72787",
      "b731b93ae98140e3b0be5310d4549ce9",
      "7a3e1186dbe341db90bba076a54dd7db"
     ]
    },
    "id": "d4814525",
    "outputId": "cb6460a2-d5f3-4395-d7cd-d56081e357a8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fit min_max_scaler and labels encoder\n",
    "X, y, le, min_max_scaler, all_labels = load_dataset(N=N)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w75FOlvafH3k",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w75FOlvafH3k",
    "outputId": "3477014e-cde7-4d14-9f70-cf09d7708011"
   },
   "outputs": [],
   "source": [
    "# save labels encoder and min_max_scaler\n",
    "le_path = os.path.join(MODEL_PATH, \"label_encoder.joblib\")\n",
    "joblib.dump(le, le_path)\n",
    "\n",
    "min_max_scaler_path = os.path.join(MODEL_PATH, \"min_max_scaler.joblib\")\n",
    "joblib.dump(min_max_scaler, min_max_scaler_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7693097c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7693097c",
    "outputId": "31bc6675-4fef-4818-f60f-50e49ba393bf"
   },
   "outputs": [],
   "source": [
    "# inspect classes distribution in train set\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "class_distr = le.inverse_transform(y_train)\n",
    "\n",
    "D = sorted( Counter(class_distr).items(), key=operator.itemgetter(1), reverse=True)\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y-wZHqE4WNr4",
   "metadata": {
    "id": "y-wZHqE4WNr4"
   },
   "outputs": [],
   "source": [
    "del X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_g9-iqQzY1CF",
   "metadata": {
    "id": "_g9-iqQzY1CF"
   },
   "outputs": [],
   "source": [
    "def create_dataset_df(N):\n",
    "  \n",
    "    spectrograms = os.listdir(SPECTROGRAMS_PATH)[:N]\n",
    "    \n",
    "    spectrograms = [i for i in spectrograms if '.npy' in i]\n",
    "    tags = [i for i in spectrograms if '.npy' in i]\n",
    "    \n",
    "    spectrograms = [os.path.join(SPECTROGRAMS_PATH, i) for i in spectrograms]\n",
    "    tags = [os.path.join(TAGS_PATH, i) for i in tags]\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df['spectrograms'] = spectrograms\n",
    "    df['tags'] = tags\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xPJHgeuuY4q-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "xPJHgeuuY4q-",
    "outputId": "be4fb078-0d6a-42cc-8dbc-97d41afcc14c"
   },
   "outputs": [],
   "source": [
    "df = create_dataset_df(N=N)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13687b30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "13687b30",
    "outputId": "0543ad6d-715a-4028-931e-094dbc3307ac"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "LATENT_DIM = 64\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 1000\n",
    "INPUT_SHAPE = x_train.shape[1]\n",
    "CONDITION_SIZE = y_train.shape[1]\n",
    "\n",
    "print('LATENT_DIM:', LATENT_DIM)\n",
    "print('CONDITION_SIZE:', CONDITION_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5lH6e9y-l_",
   "metadata": {
    "id": "1a5lH6e9y-l_"
   },
   "outputs": [],
   "source": [
    "# save all training params\n",
    "params = {}\n",
    "params['DATASET'] = N\n",
    "params['BATCH_SIZE'] = BATCH_SIZE\n",
    "params['LATENT_DIM'] = LATENT_DIM\n",
    "params['LEARNING_RATE'] = LEARNING_RATE\n",
    "params['EPOCHS'] = EPOCHS\n",
    "params['INPUT_SHAPE'] = INPUT_SHAPE\n",
    "params['CONDITION_SIZE'] = CONDITION_SIZE\n",
    "params['LABELS'] = all_labels\n",
    "\n",
    "with open(os.path.join(MODEL_PATH, 'training_params.json'), 'w') as outfile:\n",
    "    json.dump(params, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1ff3f3",
   "metadata": {
    "id": "cc1ff3f3"
   },
   "outputs": [],
   "source": [
    "# sampling\n",
    "def sampling(args, latent_dim=LATENT_DIM):\n",
    "    mean, log_var = args\n",
    "    eps = tf.random.normal(shape=(tf.shape(mean)[0], latent_dim), mean=0., stddev=1.0)\n",
    "    return mean + tf.exp(log_var/2.) * eps\n",
    "\n",
    "## encoder\n",
    "def make_encoder(input_shape=INPUT_SHAPE,\n",
    "                 latent_dim=LATENT_DIM, \n",
    "                 condition_size=CONDITION_SIZE, \n",
    "                 batch_size=BATCH_SIZE):\n",
    "    \n",
    "    x = layers.Input(shape=(input_shape,))\n",
    "    c = layers.Input(shape=(condition_size,))\n",
    "    inputs = layers.concatenate([x,c],axis=1)\n",
    "    h = layers.Dense(units=512,activation='relu')(inputs)\n",
    "    h = layers.Dense(units=512,activation='relu')(h)#\n",
    "    h = layers.Dense(units=512,activation='relu')(h)#\n",
    "    h = layers.Dense(units=512,activation='relu')(h)#\n",
    "    h = layers.Dense(units=256,activation='relu')(h)\n",
    "    mean = layers.Dense(units=latent_dim)(h)\n",
    "    log_var = layers.Dense(units=latent_dim)(h)\n",
    "    return tf.keras.Model(inputs=[x,c],outputs=[mean,log_var], name='encoder')\n",
    "\n",
    "\n",
    "## decoder\n",
    "def make_decoder(output_shape=INPUT_SHAPE, \n",
    "                 batch_size=BATCH_SIZE, \n",
    "                 latent_dim=LATENT_DIM, \n",
    "                 condition_size=CONDITION_SIZE):\n",
    "    \n",
    "    z = layers.Input(shape=(latent_dim,))\n",
    "    c = layers.Input(shape=(condition_size,))\n",
    "    con = layers.concatenate([z, c], axis=1)\n",
    "    h1 = layers.Dense(units=256,activation='relu')(con)\n",
    "    h2 = layers.Dense(units=512,activation='relu')(h1)\n",
    "    y = layers.Dense(units=output_shape,activation='sigmoid')(h2)\n",
    "    return tf.keras.Model(inputs=[z,c],outputs=y, name='decoder')\n",
    "\n",
    "## loss\n",
    "def loss(x, y, mean, log_var, alpha=1.0, beta=1.0):\n",
    "    reconstruction_loss = tf.keras.losses.mean_squared_error(y_true=x, y_pred=y)\n",
    "    reconstruction_loss = tf.reduce_mean(reconstruction_loss, name='recon_loss')\n",
    "    kl_loss = - 0.5 * tf.reduce_mean(log_var - tf.square(mean) - tf.exp(log_var) + 1)\n",
    "    kl_loss = tf.identity(kl_loss, name=\"kl_loss\")\n",
    "    cvae_loss = alpha*reconstruction_loss + beta*kl_loss\n",
    "    return cvae_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7d826e",
   "metadata": {
    "id": "cf7d826e"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "  # making encoder and decoder models\n",
    "  encoder = make_encoder()\n",
    "  #print(encoder.summary(),'\\n\\n********************************\\n\\n')\n",
    "  decoder = make_decoder()\n",
    "  #print(decoder.summary(),'\\n\\n********************************\\n\\n')\n",
    "\n",
    "  # CVAE\n",
    "  x = layers.Input(shape=(INPUT_SHAPE,))\n",
    "  c = layers.Input(shape=(CONDITION_SIZE,))\n",
    "  mean, log_var = encoder([x,c])\n",
    "  z = layers.Lambda(sampling)([mean, log_var])\n",
    "  y = decoder([z,c])\n",
    "\n",
    "  cvae = tf.keras.Model(inputs=[x, c], outputs=y, name='cvae')\n",
    "  cvae.add_loss(loss(x, y, mean,log_var, alpha=10))\n",
    "  cvae.compile(optimizer=tf.keras.optimizers.Adam(LEARNING_RATE))\n",
    "  #print(cvae.summary())\n",
    "\n",
    "  return encoder, decoder, cvae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97wjq0HVncfe",
   "metadata": {
    "id": "97wjq0HVncfe"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541e7a39",
   "metadata": {
    "id": "541e7a39",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## train\n",
    "encoder, decoder, cvae = build_model()\n",
    "cvae.fit((x_train, y_train), \n",
    "         epochs=EPOCHS, \n",
    "         batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bvuxwfc4ZMmU",
   "metadata": {
    "cellView": "form",
    "id": "bvuxwfc4ZMmU"
   },
   "outputs": [],
   "source": [
    "#@title #### [commented] fit with generator code\n",
    "xxx = \"\"\"\n",
    "continue_training = False\n",
    "\n",
    "encoder, decoder, cvae = build_model()\n",
    "\n",
    "if continue_training:\n",
    "    print('Continuing training')\n",
    "    cvae.load_weights(os.path.join(MODEL_PATH, 'vae.h5'))\n",
    "    \n",
    "else:\n",
    "    print('Train from scratch')\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                        MODEL_PATH,\n",
    "                        monitor=\"val_loss\",\n",
    "                        verbose=0,\n",
    "                        save_best_only=True,\n",
    "                        save_weights_only=False,\n",
    "                        mode=\"auto\",\n",
    "                        save_freq=\"epoch\",\n",
    "                        options=None\n",
    "                    )\n",
    "\n",
    "# generator\n",
    "training_generator = DataGenerator(df, le, min_max_scaler, batch_size=BATCH_SIZE)\n",
    "validation_generator = DataGenerator(df, le, min_max_scaler, batch_size=BATCH_SIZE)\n",
    "\n",
    "# train\n",
    "cvae.fit(training_generator, \n",
    "        epochs=EPOCHS,\n",
    "        validation_data=validation_generator,\n",
    "        #callbacks=[model_checkpoint_callback],\n",
    "        use_multiprocessing=True,\n",
    "        workers=24)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e096e580",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e096e580",
    "outputId": "75e508f6-63ca-440c-a9ce-00ff176ab308",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "cvae.save(MODEL_PATH)\n",
    "\n",
    "encoder.save( os.path.join(MODEL_PATH, 'encoder.h5') )\n",
    "decoder.save( os.path.join(MODEL_PATH, 'decoder.h5') )\n",
    "cvae.save( os.path.join(MODEL_PATH, 'vae.h5') )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3f835c",
   "metadata": {
    "id": "9a3f835c"
   },
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbb302a",
   "metadata": {
    "id": "3cbb302a"
   },
   "outputs": [],
   "source": [
    "# params\n",
    "SR = 16000 #22050\n",
    "FFT_HOP = 256\n",
    "FFT_SIZE = 512\n",
    "N_MELS = 96\n",
    "N_ITER = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55668c0",
   "metadata": {
    "id": "f55668c0"
   },
   "outputs": [],
   "source": [
    "def mel2audio(signal, save=False):\n",
    "\n",
    "    signal = min_max_scaler.inverse_transform(signal)\n",
    "\n",
    "    plt.imshow(signal)\n",
    "\n",
    "    # convert melspec back to audio\n",
    "    # Invert mel-spectrogram\n",
    "    S_inv = librosa.feature.inverse.mel_to_stft(signal, sr=SR, n_fft=FFT_HOP*4)\n",
    "    y = librosa.griffinlim(S_inv, n_iter=N_ITER, hop_length=FFT_HOP)\n",
    "    \n",
    "    duration = librosa.get_duration(y=y, sr=SR)\n",
    "    \n",
    "    if save:\n",
    "      filename = ''.join(random.choice(letters) for i in range(10))\n",
    "      path = os.path.join(GEN_PATH, 'j' + '.wav')\n",
    "      sf.write(path, y, SR, 'PCM_24')\n",
    "    \n",
    "    return y\n",
    "\n",
    "def mel2audio(mel):\n",
    "\n",
    "    y = librosa.feature.inverse.mel_to_audio(mel, \n",
    "                                         sr=SR, \n",
    "                                         n_fft=FFT_SIZE, \n",
    "                                         hop_length=FFT_HOP, \n",
    "                                         win_length=FFT_SIZE, \n",
    "                                         window='hann', \n",
    "                                         center=True, \n",
    "                                         pad_mode='reflect', \n",
    "                                         power=2.0, \n",
    "                                         n_iter=32, \n",
    "                                         length=None)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PBr4J8I0yRHB",
   "metadata": {
    "id": "PBr4J8I0yRHB"
   },
   "outputs": [],
   "source": [
    "#all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcf7ee1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "id": "6fcf7ee1",
    "outputId": "06487e46-90e5-42b6-c11d-a47785a56360",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# select label\n",
    "lab = 'electronic'\n",
    "#lab = all_labels[11]\n",
    "print(lab)\n",
    "\n",
    "cond_vec = le.transform([lab])\n",
    "\n",
    "# if cond vector over all tags\n",
    "#cond_vec = np.random.uniform(low=0, high=1, size=(CONDITION_SIZE,)).reshape(1,-1)\n",
    "\n",
    "z_sample = tf.random.normal(shape=(CONDITION_SIZE, LATENT_DIM))\n",
    "generated = decoder.predict([z_sample, np.repeat(cond_vec, CONDITION_SIZE, axis=0)],steps=1)\\\n",
    "            .reshape(CONDITION_SIZE, 96, 188)\n",
    "\n",
    "print(generated.shape)\n",
    "\n",
    "idx = 3\n",
    "\n",
    "signal = generated[idx,:,:]\n",
    "\n",
    "y = mel2audio(signal)\n",
    "ipd.Audio(y, rate=SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b5090a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "62b5090a",
    "outputId": "272ef5ba-1eb7-4028-aa1b-5c6a07220eed"
   },
   "outputs": [],
   "source": [
    "# PLOT TRAIN SAMPLE\n",
    "j = x_train[1].reshape(96, 188)\n",
    "j = x_train[19].reshape(96, 188)\n",
    "\n",
    "y = mel2audio(j)\n",
    "ipd.Audio(y, rate=SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e825bdd9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "id": "e825bdd9",
    "outputId": "61c26947-3cb2-4213-b4d5-d1abc719e7e2"
   },
   "outputs": [],
   "source": [
    "## plot latent space\n",
    "n = 60000\n",
    "mean, logvar = encoder.predict([x_train[:n,:], y_train[:n,:]])\n",
    "\n",
    "labels = le.inverse_transform(y_train)\n",
    "\n",
    "cmap = sns.color_palette(\"hls\", len(all_labels))\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.scatterplot(x=mean[:,0], y=mean[:,1], hue=labels) #, palette=cmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i8PtslcRyxma",
   "metadata": {
    "id": "i8PtslcRyxma"
   },
   "outputs": [],
   "source": [
    "if os.path.exists(GEN_PATH) and os.path.isdir(GEN_PATH):\n",
    "    shutil.rmtree(GEN_PATH)\n",
    "    os.mkdir(GEN_PATH)\n",
    "else:\n",
    "    os.mkdir(GEN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcff849",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7dcff849",
    "outputId": "f37f999b-2f3a-4c3a-b02b-c9285db2078b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## plot generated images\n",
    "for cond_tag in all_labels:\n",
    "    \n",
    "    cond_vec = le.transform([cond_tag])\n",
    "    \n",
    "    #cond_vec = np.random.uniform(low=0, high=1, size=(CONDITION_SIZE,)).reshape(1,-1)\n",
    "    \n",
    "    z_sample = tf.random.normal(shape=(CONDITION_SIZE, LATENT_DIM))\n",
    "    generated = decoder.predict([z_sample, np.repeat(cond_vec, CONDITION_SIZE, axis=0)],steps=1).reshape(CONDITION_SIZE, 188, 96)\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    \n",
    "    for i in range(3):\n",
    "        \n",
    "        #signal = generated[i,:,:].reshape(96, 188)\n",
    "        signal = generated[i].reshape(96, 188)\n",
    "        \n",
    "        plt.subplot(1, 5, i+1)\n",
    "        plt.axis('off')\n",
    "        plt.title(str(cond_tag))\n",
    "        plt.imshow(signal) #, cmap='gray')\n",
    "        \n",
    "        save_audio = False\n",
    "        \n",
    "        if save_audio:\n",
    "            \n",
    "            y = mel2audio(signal)\n",
    "            #ipd.Audio(y, rate=SR)\n",
    "            filename = ''.join(random.choice(letters) for i in range(3))\n",
    "            path = os.path.join(GEN_PATH, cond_tag + '_' + filename + '.wav')\n",
    "            sf.write(path, y, SR, 'PCM_24')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2.1. condVAEmusic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "072b13566d0c454781d3bdc78be72787": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14704cfcae504cf884a9fb606ee1c22e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_547d6c8a2ce34c73a304b1779ce50878",
       "IPY_MODEL_7e4f2ecbbfed4c09b568afbaa7547866"
      ],
      "layout": "IPY_MODEL_d591c34a6fc645ffbb690d058cd10898"
     }
    },
    "547d6c8a2ce34c73a304b1779ce50878": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": " 59%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_072b13566d0c454781d3bdc78be72787",
      "max": 4423,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7cf1bf0ba5a4492cacd8151e4cbab1d4",
      "value": 2603
     }
    },
    "7a3e1186dbe341db90bba076a54dd7db": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7cf1bf0ba5a4492cacd8151e4cbab1d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "7e4f2ecbbfed4c09b568afbaa7547866": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a3e1186dbe341db90bba076a54dd7db",
      "placeholder": "​",
      "style": "IPY_MODEL_b731b93ae98140e3b0be5310d4549ce9",
      "value": " 2603/4423 [22:38&lt;16:05,  1.88it/s]"
     }
    },
    "b731b93ae98140e3b0be5310d4549ce9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d591c34a6fc645ffbb690d058cd10898": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
